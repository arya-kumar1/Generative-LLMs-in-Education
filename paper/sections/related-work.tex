\section{Related Work}
\label{sec:related}

Research on the educational effectiveness of online information sources has
highlighted both the potential and the challenges of open knowledge platforms such as
Wikipedia. \citet{reagle2010good} examined how collaborative editing shapes article quality
and reliability, while \citet{worku2020exploring} explored how students use Wikipedia as a
learning supplement rather than a primary instructional source.

Within educational psychology, studies such as \citet{pithers2000critical} and
\citet{ekholm2018clarifying} have emphasized that effective learning materials share
qualities of coherence, conceptual clarity, and scaffolding---all of which inform how
learners construct and evaluate understanding. More recently,
\citet{catlr2019selfexplanation} and \citet{fadhly2022efl} have shown that linguistic
structure and readability strongly predict comprehension and recall in self-directed
learning.

At the same time, large language models (LLMs) have begun to assist learners through
Socratic and chain-of-thought (CoT) tutoring approaches. \citet{ding2024socratic}
demonstrated that prompting LLMs with step-by-step reasoning can promote reflective
thinking, while \citet{kestin2025aitutor} evaluated the use of AI tutors for conceptual
understanding in STEM contexts. OpenAI’s recent Apps SDK
\cite{openaiAppsSDK} has further simplified dynamic integration of APIs like Wikipedia’s
REST interface \cite{wikimediaREST}, enabling models to fetch and analyze real-world
content directly.

Building on this literature, our project connects insights from instructional design and
critical thinking research with CoT-based LLM evaluation. We aim to bridge a gap between
educational theory and automated text analysis by training a model that can diagnose the
pedagogical quality of Wikipedia articles.
