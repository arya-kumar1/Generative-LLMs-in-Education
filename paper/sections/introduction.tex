% Introduction
% Structure: Problem/Motivation -> Background -> Research Questions -> Contributions -> Paper Outline

\section{Introduction}

\textbf{Motivation.} Wikipedia is among the most frequently consulted learning resources, yet the instructional quality of its articles is uneven. As generative AI becomes embedded in study workflows, there is an opportunity to use large language models (LLMs) not only to summarize content but to \emph{diagnose} whether an article supports effective learning.

\textbf{Background.} Prior work in educational psychology and instructional design highlights the importance of coherence, scaffolding, conceptual density, and self-explanation for learning effectiveness \cite{ekholm2018clarifying, pithers2000critical, catlr2019selfexplanation}. Recent studies further show that AI tutors designed with research-based reasoning strategies can meet or even exceed active learning classrooms \cite{kestin2025aitutor}, and that Socratic, step-by-step guidance (including Chain-of-Thought prompting) can preserve critical thinking while improving problem-solving \cite{ding2024socratic, ibm2025cot}. In parallel, Wikipedia’s governance and quality dynamics have been extensively studied \cite{reagle2010good, worku2020exploring}.

\textbf{Research questions.} This paper investigates:
\begin{enumerate}
  \item Which textual and structural characteristics make Wikipedia articles effective for learning according to established educational psychology research?
  \item Can an LLM be trained to diagnose the quality of a Wikipedia article using these characteristics?
  \item How does the model’s assessment compare to human expert judgments of article quality?
  \item What are the implications for AI-assisted learning and the reliability of open educational resources?
\end{enumerate}

\textbf{Contributions.} The main contributions are:
\begin{itemize}
  \item A synthesis of linguistic/structural features linked to educational effectiveness (e.g., coherence, hierarchy depth, example density, readability).
  \item A Chain-of-Thought (CoT) LLM “Wiki Diagnostic Tutor” that retrieves Wikipedia content via API and classifies articles as \emph{effective/neutral/ineffective} with interpretable rationales.
  \item An evaluation comparing automated metrics to expert educator ratings, plus ablations quantifying which features matter most.
  \item A reproducible pipeline and dataset of article summaries and human rubric scores for future research.
\end{itemize}

\textbf{Paper outline.} Section~\ref{sec:related} reviews related work. Section~\ref{sec:methodology} details data and methods. Section~\ref{sec:results} reports findings. Section~\ref{sec:discussion} discusses implications and limitations. Section~\ref{sec:conclusion} concludes.
