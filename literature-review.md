# Literature Review

Kestin, Greg, et al. "AI tutoring outperforms in-class active learning: an RCT introducing a novel research-based design in an authentic educational setting." Scientific Reports 15.1 (2025): 17458.
[pdf](https://www.nature.com/articles/s41598-025-97652-6)

A recent Nature Scientific Reports study demonstrated that AI tutors designed with structured reasoning strategies can outperform even active learning classrooms in fostering student engagement and comprehension.
The research highlights how step-by-step problem-solving methods embedded in AI tutors lead to significant improvements in learning outcomes.
These findings underscore the potential of generative AI to not only match but exceed traditional pedagogical techniques when carefully designed.

Ding, Yuyang, et al. "Boosting large language models with socratic method for conversational mathematics teaching." Proceedings of the 33rd ACM International Conference on Information and Knowledge Management. 2024.
[pdf](https://dl.acm.org/doi/abs/10.1145/3627673.3679881)

At CHI 2024, researchers explored how large language models can be tailored to support education without encouraging overreliance on direct answers.
Their findings emphasize that scaffolding approaches, where models guide rather than solve, help preserve critical thinking in students.
The study contributes to ongoing debates about balancing efficiency with deeper cognitive engagement in AI-assisted learning.

Gadesha, Vrunda, et al. “What Is Chain of Thought (COT) Prompting?” IBM, 14 July 2025, 
[pdf](https://www.ibm.com/think/topics/chain-of-thoughts)

IBM’s exploration of chain-of-thought prompting illustrates how step-by-step reasoning improves both accuracy and interpretability of AI systems.
This method parallels the well-documented benefits of human self-explanation in educational psychology.
By mirroring cognitive processes, chain-of-thought enables LLMs to function as more effective teaching partners rather than mere answer generators.

“The Power of Self-Explanation.” Center for Advancing Teaching and Learning Through Research, 3 Dec. 2019, 
[pdf](https://learning.northeastern.edu/the-power-of-self-explanation/)

Self-explanation requires learners to articulate their reasoning while working through a problem, which helps them forge links between new information and prior knowledge.
Empirical studies show that prompting learners to generate explanations during the learning process yields greater gains than simply reviewing or re-reading material.
The effectiveness of self-explanation spans diverse learner abilities and instructional settings, from direct instruction to discovery learning.
This links back to CoT since it's evident that AI and humans both beneift from step by step explaniation,exploration, and reasoning.

Pithers, Robert T., and Rebecca Soden. "Critical thinking in education: A review." Educational research 42.3 (2000): 237-249.
[pdf](https://www.tandfonline.com/doi/abs/10.1080/001318800440579)
Melisa, Rahyuni, et al. (2025) examine how ChatGPT influences students’ development of critical thinking, evaluation, and independent judgment in higher education, making it 
relevant as universities have to decide on their limitations of AI with both the opportunities and risks of integrating it into learning. The paper uses a systematic literature 
review, using structured database searches (Scopus and ERIC) and algorithmic screening criteria to use data from different publications.


Pithers, Robert T., and Rebecca Soden. "Critical thinking in education: A review." Educational research 42.3 (2000): 237-249.
[pdf](https://www.tandfonline.com/doi/abs/10.1080/001318800440579?casa_token=Vp5pgv1_OlkAAAAA:CJISdbN5cp1w1L0sEMG5dHCVasGKpRwVWVDiBzoPC4rtJ7P2hp7nVkjy7KmxyPB6PXfPgUoNavQw6Q)
Pithers, Robert T., and Rebecca Soden (2000) review how critical thinking has been defined, taught, and measured across different levels of education. The methodology is a 
systematic literature review, where the authors analyze and integrate findings from psychological and educational research.
